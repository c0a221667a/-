import csv
from collections import defaultdict
from datetime import datetime
from statistics import median
import os

# å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
INPUT_FILE = 'log_test.csv'

def calculate_and_compare_logs():
    """
    ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¸­å¤®å€¤ã‚’è¨ˆç®—ã—ã€å„ã‚³ãƒ³ãƒ†ãƒŠã®æœ€æ–°ã®ãƒ­ã‚°ä»¶æ•°ã¨æ¯”è¼ƒã—ã¦ã€çµæœã‚’ã€Œç•°å¸¸ã‚ã‚Šã€ã¨ã€Œç•°å¸¸ãªã—ã€ã«åˆ†ã‘ã¦å‡ºåŠ›ã—ã¾ã™ã€‚
    """
    if not os.path.exists(INPUT_FILE):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« '{INPUT_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ³ãƒ†ãƒŠåã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€å„ã‚³ãƒ³ãƒ†ãƒŠã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ãƒ­ã‚°ä»¶æ•°ã‚’ä¿å­˜
    container_data = defaultdict(list)
    
    try:
        with open(INPUT_FILE, mode='r', newline='', encoding='utf-8') as f:
            reader = csv.reader(f)
            header = next(reader)  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—

            for row in reader:
                if len(row) < 4:
                    continue  # ä¸æ­£ãªè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                
                time_str, container_name, log_count_str, _ = row
                log_count = int(log_count_str)
                
                time_obj = datetime.strptime(time_str, '%Y-%m-%d %H:%M')
                
                # ã‚³ãƒ³ãƒ†ãƒŠåã”ã¨ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ãƒ­ã‚°ä»¶æ•°ã®ã‚¿ãƒ—ãƒ«ã‚’ä¿å­˜
                container_data[container_name].append((time_obj, log_count))

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ - {e}")
        return

    abnormal_containers = []
    normal_containers = []

    # å„ã‚³ãƒ³ãƒ†ãƒŠã®ä¸­å¤®å€¤ã‚’è¨ˆç®—ã—ã€æœ€æ–°ã®ãƒ­ã‚°ä»¶æ•°ã¨æ¯”è¼ƒ
    for container_name, timeseries_list in container_data.items():
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆã—ã¦ã€æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ç‰¹å®š
        timeseries_list.sort(key=lambda x: x[0], reverse=True)
        
        # éå»ã®ãƒ‡ãƒ¼ã‚¿ãŒ1ã¤ã‚‚ãªã„å ´åˆã¯æ¯”è¼ƒã§ããªã„
        if len(timeseries_list) < 2:
            continue
            
        # æœ€æ–°ã®ãƒ­ã‚°ä»¶æ•°ã‚’å–å¾—
        latest_timestamp, latest_count = timeseries_list[0]
        
        # æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’é™¤ã„ãŸéå»ã®ãƒ­ã‚°ä»¶æ•°ã‚’å–å¾—
        past_counts = [count for _, count in timeseries_list[1:]]
        
        # ä¸­å¤®å€¤ã‚’è¨ˆç®—
        median_count = median(past_counts)

        # æœ€æ–°ã®ãƒ­ã‚°ä»¶æ•°ãŒä¸­å¤®å€¤ã‚ˆã‚Šå¤§ããã€ã‹ã¤ãã®å·®ãŒ1000ä»¥ä¸Šã®å ´åˆã€ç•°å¸¸ã‚ã‚Šã¨åˆ¤æ–­
        if latest_count > median_count and (latest_count - median_count) >= 1000:
            abnormal_containers.append((container_name, latest_count, median_count))
        # æœ€æ–°ã®ãƒ­ã‚°ä»¶æ•°ãŒä¸­å¤®å€¤ä»¥ä¸‹ã€ã¾ãŸã¯å·®ãŒ1000æœªæº€ã®å ´åˆã€ç•°å¸¸ãªã—ã¨åˆ¤æ–­
        else:
            normal_containers.append((container_name, latest_count, median_count))
            
    # åˆ†æçµæœã‚’å‡ºåŠ›
    if abnormal_containers:
        print("ğŸ”´ ç•°å¸¸ã‚ã‚Š (ãƒ­ã‚°ä»¶æ•°ãŒä¸­å¤®å€¤ã‚ˆã‚Šå¤šãã€ãã®å·®ãŒ1000ä»¥ä¸Šã®ã‚³ãƒ³ãƒ†ãƒŠ):")
        for container_name, latest_count, median_count in abnormal_containers:
            print(f"  - {container_name} (æœ€æ–°: {latest_count}, ä¸­å¤®å€¤: {median_count})")
    else:
        print("âœ… ãƒ­ã‚°ä»¶æ•°ãŒä¸­å¤®å€¤ã‚ˆã‚Šå¤šãã€ã‹ã¤ãã®å·®ãŒ1000ä»¥ä¸Šã®ã‚³ãƒ³ãƒ†ãƒŠã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    print("\n------------------------------------------")

    if normal_containers:
        print("ğŸŸ¢ ç•°å¸¸ãªã— (ä¸Šè¨˜ã®æ¡ä»¶ã«è©²å½“ã—ãªã„ã‚³ãƒ³ãƒ†ãƒŠ):")
        for container_name, latest_count, median_count in normal_containers:
            print(f"  - {container_name} (æœ€æ–°: {latest_count}, ä¸­å¤®å€¤: {median_count})")
    else:
        print("éå»ã®ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒå¯èƒ½ãªã‚³ãƒ³ãƒ†ãƒŠã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    calculate_and_compare_logs()